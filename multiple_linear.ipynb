{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00000-26c1c61e-9318-4993-ae63-69a84f6e5bab",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "3b9226f1",
        "execution_millis": 5,
        "execution_start": 1618928228851,
        "deepnote_cell_type": "code"
      },
      "source": "%matplotlib inline\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nfrom matplotlib import pyplot as plt\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\n\nimport numpy.polynomial.polynomial as poly",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00001-7779078b-da7b-4d14-b89b-599354ec7fec",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "32adc213",
        "execution_millis": 1,
        "execution_start": 1618928020159,
        "deepnote_cell_type": "code"
      },
      "source": "def get_clean_data(file):\n    # Reads panadas dataframe\n    df = pd.read_csv(file)\n    # Convert datetime to a number\n    df['SALE DATE'] = pd.to_datetime(df['SALE DATE']).astype(np.int64)\n    # Drop other unneeded columns\n    data = df.drop(columns = [\"NEIGHBORHOOD\", \"APARTMENT NUMBER\", \"BUILDING CLASS CATEGORY\", \"TAX CLASS AT PRESENT\", \"BUILDING CLASS AT PRESENT\", \"BOROUGH\", \"EASE-MENT\", \"ADDRESS\", \"ZIP CODE\", \"BUILDING CLASS AT TIME OF SALE\", \"TOTAL UNITS\"])\n    # Convert all other strings to int values\n    data = data.astype(int)\n    # print(x.info())\n    return data",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-45433e3b-816e-443b-862e-57572ffcfe41",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "2a2bdb50",
        "execution_start": 1618576698695,
        "execution_millis": 4,
        "deepnote_cell_type": "code"
      },
      "source": "def no_feature_scaling(df):\n    df_x = df[[\"BLOCK\",\"LOT\",\"RESIDENTIAL UNITS\",\"COMMERCIAL UNITS\",\"LAND SQUARE FEET\", \"GROSS SQUARE FEET\",\"YEAR BUILT\",\"TAX CLASS AT TIME OF SALE\",\"SALE DATE\"]]\n    df_y = df[[\"SALE PRICE\"]]\n\n    x_array = np.array(df_x)\n    y_array = np.array(df_y)\n    \n    X_train, X_test, y_train, y_test = train_test_split(x_array, y_array, test_size = 0.15, train_size = 0.85)\n    return X_train, y_train",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-468042d3-f6cb-42c9-8e5d-9232d3a95336",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "ec7a11a",
        "execution_millis": 2,
        "execution_start": 1618582235412,
        "deepnote_cell_type": "code"
      },
      "source": "def preprocess_scale_data(df):\n    df_x_prescale = df[[\"BLOCK\",\"LOT\",\"RESIDENTIAL UNITS\",\"COMMERCIAL UNITS\",\"LAND SQUARE FEET\", \"GROSS SQUARE FEET\",\"YEAR BUILT\",\"TAX CLASS AT TIME OF SALE\",\"SALE DATE\"]]\n    df_y = df[[\"SALE PRICE\"]]\n\n    x_scaled_array = preprocessing.scale(df_x_prescale)\n    y_scaled_array = preprocessing.scale(df_y)\n    # y_array = np.array(df_y)\n    \n    # test_size = 0.8, train_size = 0.2\n    # test_size = 0.15, train_size = 0.85\n    X_train, X_test, y_train, y_test = train_test_split(x_scaled_array, y_scaled_array, test_size = 0.8, train_size = 0.2)\n    return X_train, y_train",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00003-bc8cc5a2-c182-4924-af05-437700e7832c",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "4560d227",
        "execution_millis": 1,
        "execution_start": 1618928023419,
        "deepnote_cell_type": "code"
      },
      "source": "def preprocess_normalize_data(df):\n    df_x_prescale = df[[\"BLOCK\",\"LOT\",\"RESIDENTIAL UNITS\",\"COMMERCIAL UNITS\",\"LAND SQUARE FEET\", \"GROSS SQUARE FEET\",\"YEAR BUILT\",\"TAX CLASS AT TIME OF SALE\",\"SALE DATE\"]]\n    df_y = df[[\"SALE PRICE\"]]\n    # print(df_x_prescale)\n\n    x_scaled_array = preprocessing.scale(df_x_prescale)\n    y_array = np.array(df_y)\n\n    df_z_scaled = df_x_prescale.copy()\n    # print(df_z_scaled)\n    # apply normalization technique to Sale Date\n    column = 'SALE DATE'\n    df_z_scaled[column] = (df_z_scaled[column] - df_z_scaled[column].mean()) / df_z_scaled[column].std()\n    # print(df_z_scaled)\n    \n    X_train, X_test, y_train, y_test = train_test_split(x_scaled_array, y_array, test_size = 0.8, train_size = 0.2)\n    return X_train, y_train\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00004-d818febd-4425-4b2a-a815-00cb7ea2eb86",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "cc5b5e8",
        "execution_millis": 2,
        "execution_start": 1618576324629,
        "deepnote_cell_type": "code"
      },
      "source": "def preprocess_standard_scalar(df):\n    df_x_prescale = df[[\"BLOCK\",\"LOT\",\"RESIDENTIAL UNITS\",\"COMMERCIAL UNITS\",\"LAND SQUARE FEET\", \"GROSS SQUARE FEET\",\"YEAR BUILT\",\"TAX CLASS AT TIME OF SALE\",\"SALE DATE\"]]\n    df_y = df[[\"SALE PRICE\"]]\n\n    x_array = np.array(df_x_prescale)\n    y_array = np.array(df_y)\n    \n    X_train, X_test, y_train, y_test = train_test_split(x_array, y_array, test_size = 0.15, train_size = 0.85)\n\n    scaler = preprocessing.StandardScaler().fit(X_train)\n    X_scaled = scaler.transform(X_train)\n\n    # scaler2 = preprocessing.StandardScaler().fit(y_train)\n    # y_scaled = scaler2.transform(y_train)\n\n    return X_scaled, y_train\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00005-f9bb5404-c1f6-4425-aef4-f255c968c270",
        "deepnote_to_be_reexecuted": false,
        "source_hash": null,
        "execution_millis": 347,
        "execution_start": 1618575988296,
        "is_code_hidden": true,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "def pre_scale_normalization():\n    # df = pd.read_csv(\"greater_than_1k.csv\")\n    # df = df.drop([\"Column1\"], axis=1)\n    # print(df)\n    # df.shape\n    # X = np.array(df)\n    # print(X)\n\n    # # Get indexes where name column has value john and \n    # # value column equals to 0.0\n    # indexNames = df[(df['SALE PRICE'] == ' -  ') & (df['value'] == 0.0)].index\n    # # Delete these row indexes from dataFramedf.drop(indexNames , inplace=True)\n\n    # df_dropped = df.drop(df.index[df['myvar'] == 'specific_name'], inplace = True)\n    # print(df_dropped)\n\n\n\n\n    df = pd.read_csv(\"greater_than_1k.csv\")\n    df = df.drop([\"Column1\"], axis=1)\n\n    #print((df['SALE PRICE'] == ' -  '))\n    # print(df['YEAR BUILT'] == 0.0)\n    null_indicies = df[(df['SALE PRICE'] == ' -  ') | (df['YEAR BUILT'] == 0.0) | (df['LAND SQUARE FEET'] == ' -  ') | (df['GROSS SQUARE FEET'] == ' -  ')].index\n    #print(len(indexNames))\n\n    df_dropped = df.drop(index = null_indicies)\n    #print(df_dropped)\n\n    #print(df_dropped['SALE PRICE'].astype(int) < 1000)\n\n    # inconsistent_sale_price_indicies = df_dropped[(df_dropped['SALE PRICE'].astype(int) < 1000)].index\n    #df_without_inconsistent = df.drop(index = inconsistent_sale_price_indicies)\n    #print(inconsistent_sale_price_indicies)\n    # print(df_dropped['SALE PRICE'].atype(int) < 1000)\n    # df_inconsistent_sale_price\n    # print(df[inconsistent_sale_price_indicies])\n\n    # df_without_inconsistent\n\n    # df_dropped.info()\n    # df_dropped\n\n    df_dropped['SALE DATE'] = pd.to_datetime(df['SALE DATE']).astype(np.int64)\n    # df_dropped[\"SALE DATE\"]\n    x = df_dropped.drop(columns = [\"NEIGHBORHOOD\", \"APARTMENT NUMBER\", \"BUILDING CLASS CATEGORY\", \"TAX CLASS AT PRESENT\", \"BUILDING CLASS AT PRESENT\", \"BOROUGH\", \"EASE-MENT\", \"ADDRESS\", \"ZIP CODE\", \"BUILDING CLASS AT TIME OF SALE\", \"TOTAL UNITS\"])\n\n    # x[\"LAND SQUARE FEET\"] = x[\"LAND SQUARE FEET\"].astype(int)\n    # x[\"GROSS SQUARE FEET\"] = x[\"GROSS SQUARE FEET\"].astype(int)\n    x = x.astype(int)\n    x.info()\n\n    #print(df[\"APARTMENT NUMBER\"].to_string())\n    #x1 = pd.to_string(df[\"APARTMENT NUMBER\"])\n\n\n\n\n\n    x_prescale = x[[\"BLOCK\",\"LOT\",\"RESIDENTIAL UNITS\",\"COMMERCIAL UNITS\",\"LAND SQUARE FEET\", \"GROSS SQUARE FEET\",\"YEAR BUILT\",\"TAX CLASS AT TIME OF SALE\",\"SALE DATE\"]]\n    y = x[[\"SALE PRICE\"]]\n    # print(x_prescale.shape)\n    x_scaled = preprocessing.scale(x_prescale)\n    #x_scaled\n    type(x_scaled)\n\n    # print(len(x_scaled[0]))\n    y_array = np.array(y)\n    X_train, X_test, y_train, y_test = train_test_split(x_scaled, y_array, test_size = 0.15, train_size = 0.85)\n\n    linear_reg = LinearRegression()\n    linear_reg.fit(X_train, y_train)\n    yhat = linear_reg.predict(X_train)\n    print(\"Coefficients\", linear_reg.coef_)\n    print(\"Intercept\", linear_reg.intercept_)\n    print(\"Score\", linear_reg.score(X_train, y_train))\n\n    # print(np.mean(yhat))\n    print(y_train)\n    RSS = np.sum((yhat - y_train)**2)\n    TSS = np.sum((y_train - np.mean(y_train))**2)\n    Rsquared = 1- RSS/TSS\n    print(\"RSS\", RSS, \"TSS\",TSS)\n    print(\"R^2\",Rsquared)\n\n\n\n\n    # copy the data\n    df_z_scaled = x_prescale.copy()\n    \n    # apply normalization technique to Sale Date\n    column = 'SALE DATE'\n    df_z_scaled[column] = (df_z_scaled[column] - df_z_scaled[column].mean()) / df_z_scaled[column].std()    \n    print(df_z_scaled)\n\n    y = x[[\"SALE PRICE\"]]\n\n    y_array = np.array(y)\n    X_train, X_test, y_train, y_test = train_test_split(x_scaled, y_array, test_size = 0.8, train_size = 0.2)\n\n    linear_reg = LinearRegression()\n    linear_reg.fit(X_train, y_train)\n    yhat = linear_reg.predict(X_train)\n    print(\"Coefficients\", linear_reg.coef_)\n    print(\"Intercept\", linear_reg.intercept_)\n    print(\"R^2 Score\", linear_reg.score(X_train, y_train))\n\n    '''\n    # print(np.mean(yhat))\n    print(y_train)\n    RSS = np.sum((yhat - y_train)**2)\n    TSS = np.sum((y_train - np.mean(y_train))**2)\n    Rsquared = 1- RSS/TSS\n    print(\"RSS\", RSS, \"TSS\",TSS)\n    print(\"R^2\",Rsquared)\n    '''\n\npre_scale_normalization()",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Regular Multiple Linear Regression",
      "metadata": {
        "tags": [],
        "cell_id": "00002-57b1272c-dcfc-498b-8924-ff618517840f",
        "deepnote_cell_type": "text-cell-h1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00003-6a2a536b-9f3c-48e4-868b-262605e9bcc7",
        "output_cleared": true,
        "source_hash": "3cbca760",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 0,
        "execution_start": 1618576028929,
        "deepnote_cell_type": "code"
      },
      "source": "def train_linear(X_train, y_train):\n    linear_reg = LinearRegression()\n    linear_reg.fit(X_train, y_train)\n\n    # yhat = linear_reg.predict(X_train)\n    # RSS = np.sum((yhat - y_train)**2)\n    # TSS = np.sum((y_train - np.mean(y_train))**2)\n    # R2 = 1- RSS/TSS\n\n    return linear_reg.coef_, linear_reg.intercept_, linear_reg.score(X_train, y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-42e9d897-8bba-4622-b44f-d5d727cd85c8",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "73a2c50",
        "execution_millis": 162,
        "execution_start": 1618576958050,
        "deepnote_cell_type": "code"
      },
      "source": "data = get_clean_data(\"cleaned_data.csv\")\n# print(data)\n# print(data.info)\n\n# X_train, y_train = no_feature_scaling(data)\n# X_train, y_train = preprocess_scale_data(data)\nX_train, y_train = preprocess_normalize_data(data)\n# X_train, y_train = preprocess_standard_scalar(data)\n\ncoef, inter, score = train_linear(X_train, y_train)\nprint(\"Coefficients\", coef)\nprint(\"Intercept\", inter)\nprint(\"Score\", score)",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Coefficients [[  -174146.51578568    565296.33223087 -18980347.02651202\n    6418837.67075773 -11760507.13736631  36680015.93984197\n    -299042.89633517  -1474957.68383601    144093.78113136]]\nIntercept [1645770.37461079]\nScore 0.8803709829580303\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n  warnings.warn(\"Numerical issues were encountered \"\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00009-bf5311e0-9891-4a4c-ab90-19510cfe8837",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "4616deaa",
        "execution_millis": 338,
        "execution_start": 1618584804018,
        "deepnote_cell_type": "code"
      },
      "source": "data = get_clean_data(\"cleaned_data.csv\")\n# print(data)\n# print(data.info)\n\nfor i in range(4):\n    if i == 0: X_train, y_train = no_feature_scaling(data)\n    elif i == 1: X_train, y_train = preprocess_scale_data(data)\n    elif i == 2: X_train, y_train = preprocess_normalize_data(data)\n    elif i == 3: X_train, y_train = preprocess_standard_scalar(data)\n\n    coef, inter, score = train_linear(X_train, y_train)\n    # print(\"Coefficients\", coef)\n    # print(\"Intercept\", inter)\n    print(\"Score\", score)",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Score 0.5512370155327757\nScore 0.31472933411675885\nScore 0.805721686151032\nScore 0.5473853066584895\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n  warnings.warn(\"Numerical issues were encountered \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n  warnings.warn(\"Numerical issues were encountered \"\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00011-9d709021-fa3c-4d37-8bf2-47b71918a8c2",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "75d450e4",
        "execution_millis": 34,
        "execution_start": 1618584859182,
        "deepnote_cell_type": "code"
      },
      "source": "data = get_clean_data(\"cleaned_data.csv\")\nX_train, y_train = preprocess_normalize_data(data)\ncoef, inter, score = train_linear(X_train, y_train)\nprint(score)\nprint(X_train.dot(coef.T) + inter)\nprint(y_train)",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "0.8395058663767565\n[[  563260.70816494]\n [ 3555199.87184169]\n [ 1319250.88817919]\n ...\n [  126869.85673512]\n [  749271.76086301]\n [-1141765.4299602 ]]\n[[345000]\n [307224]\n [995000]\n ...\n [665000]\n [712775]\n [433890]]\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n  warnings.warn(\"Numerical issues were encountered \"\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "# Polynomial Feature Transformation",
      "metadata": {
        "tags": [],
        "cell_id": "00011-30e2417e-177d-492d-b365-75e77fdec148",
        "deepnote_cell_type": "text-cell-h1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00010-0e8937c4-6ec8-4ca0-8b0a-640cf709ccd8",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "be57cadd",
        "execution_millis": 0,
        "execution_start": 1618583507702,
        "deepnote_cell_type": "code"
      },
      "source": "def polynomial_regression(X_train, y_train, degree):\n    poly_features = preprocessing.PolynomialFeatures(degree = degree, include_bias = False)\n    print(X_train)\n    X_poly = poly_features.fit_transform(X_train)\n    return X_poly",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00013-038f6f61-3f4f-4b02-bff2-4f4ad0d59246",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "3a4f7325",
        "execution_millis": 2,
        "execution_start": 1618583148667,
        "is_code_hidden": true,
        "deepnote_cell_type": "code"
      },
      "source": "def polynomial_regression2(X_tr, y_tr):\n    validation_costs = []\n    train_costs = []\n    theta_dict = {}\n    model_degree = range(1, 11)\n\n    for d in model_degree:\n        # print('Order: ', d)\n        theta = poly.polyfit(X_tr, y_tr, d)\n        yhat = poly.polyval(X_val, theta)\n        validation_cost = np.mean((yhat - y_val) ** 2)\n        theta_dict[d] = theta\n        validation_costs.append(validation_cost)\n        # # if d == 1:\n        # w0 = theta[0]\n        # w1 = theta[1]\n        # for j in range(10):\n        #   x1 = X_val[j]\n        #   yhet1 = w0 + w1 * x1\n        #   print(\"yhet1\", yhet1)\n        # print('Theta: ', theta)\n        # print(\"Validation Cost: \", validation_costs)\n        # print(\"yhat: \", yhat)\n        yhat_train = poly.polyval(X_tr, theta)\n        train_cost = np.mean((yhat_train - y_tr) ** 2)\n        train_costs.append(train_cost)\n        # print('Train cost: ', train_cost)\n        # print('-------------------------')\n\n    # print(\"Train Costs:\", train_costs)\n    # print(\"Validation Costs:\", validation_costs)\n    # min_cost_index = np.argmin(validation_costs)\n    # print(\"Best Model Degree:\", min_cost_index + 1)\n    # print(theta_dict[min_cost_index + 1])",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00013-fd46285f-4465-4695-ae44-35e77b59e82a",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "737fa8bb",
        "execution_millis": 43,
        "output_cleared": false,
        "execution_start": 1618584968004,
        "deepnote_cell_type": "code"
      },
      "source": "data = get_clean_data(\"cleaned_data.csv\")\nX_train, y_train = preprocess_normalize_data(data)\nX_poly = polynomial_regression(X_train, y_train, 2)\n# X_poly = polynomial_regression2(X_train, y_train)\ncoef, inter, score = train_linear(X_poly, y_train)\n# print(\"Coefficients\", coef)\n# print(\"Intercept\", inter)\nprint(\"Score\", score)",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[[-0.80552242 -0.44624325 -0.13824403 ...  0.28725656  3.4944635\n  -0.04485267]\n [-0.32463718 -0.43155889 -0.13824403 ... -4.46976288  3.4944635\n  -0.64886243]\n [ 0.6839281  -0.33086616 -0.08193742 ...  0.17152573 -0.55614862\n   0.74131876]\n ...\n [ 0.5039058  -0.34764828 -0.08193742 ...  0.31618927 -0.55614862\n   1.30697869]\n [ 0.33406825 -0.2679332  -0.08193742 ...  0.38852104 -0.55614862\n  -0.87896138]\n [-0.54897689 -0.38121253  0.19959563 ...  0.18599209  0.79405542\n  -0.84061156]]\nScore 0.9828645889712995\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n  warnings.warn(\"Numerical issues were encountered \"\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00014-47022b08-5d4f-4fc2-9164-a81245dbd316",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "d4faa3f9",
        "execution_millis": 10,
        "execution_start": 1618584969640,
        "deepnote_cell_type": "code"
      },
      "source": "print(X_poly.dot(coef.T) + inter)\nprint(y_train)",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[[10848150.08484664]\n [-2168184.08086241]\n [  393490.96663062]\n ...\n [  131077.66710808]\n [   90243.72649328]\n [ 2620967.46971145]]\n[[1400000]\n [ 500000]\n [ 800000]\n ...\n [ 510000]\n [1812485]\n [ 999000]]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "# Ridge Regularization",
      "metadata": {
        "tags": [],
        "cell_id": "00017-7debc3d4-d96a-430d-99b9-efac3e7826fa",
        "deepnote_cell_type": "text-cell-h1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00017-72be972c-8d48-44d5-bcb9-d5047b9f9adf",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "21017019",
        "execution_millis": 1,
        "execution_start": 1618585456182,
        "deepnote_cell_type": "code"
      },
      "source": "def ridge_regularization(X_train, y_train, alpha):\n    reg = Ridge(alpha=alpha)\n    reg.fit(X_train, y_train)\n    return reg.coef_, reg.intercept_, reg.score(X_train, y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00019-9a2234a2-4f69-4632-ab0b-b81ab12904dd",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "5e40167d",
        "execution_millis": 27,
        "execution_start": 1618585521208,
        "deepnote_cell_type": "code"
      },
      "source": "data = get_clean_data(\"cleaned_data.csv\")\nX_train, y_train = preprocess_normalize_data(data)\ncoef, inter, score = ridge_regularization(X_train, y_train, 0.5)\n# print(\"Coefficients\", coef)\n# print(\"Intercept\", inter)\nprint(\"Score\", score)",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Score 0.8305372055063678\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n  warnings.warn(\"Numerical issues were encountered \"\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00020-1a16a070-c625-4a6b-b01a-5b5ccd6ac07c",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "a94aea5",
        "execution_millis": 62,
        "execution_start": 1618585525010,
        "deepnote_cell_type": "code"
      },
      "source": "data = get_clean_data(\"cleaned_data.csv\")\nX_train, y_train = preprocess_normalize_data(data)\nridge_alpha_space = np.linspace(0,1,11)\nfor i in ridge_alpha_space:\n    coef, inter, score = ridge_regularization(X_train, y_train, i)\n    # print(\"Coefficients\", coef)\n    # print(\"Intercept\", inter)\n    print(\"Alpha\", i, \"Score\", score)",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Alpha 0.0 Score 0.833618302972984\nAlpha 0.1 Score 0.8336183024573919\nAlpha 0.2 Score 0.8336183009108071\nAlpha 0.30000000000000004 Score 0.8336182983335161\nAlpha 0.4 Score 0.8336182947258055\nAlpha 0.5 Score 0.8336182900879621\nAlpha 0.6000000000000001 Score 0.8336182844202719\nAlpha 0.7000000000000001 Score 0.8336182777230211\nAlpha 0.8 Score 0.8336182699964959\nAlpha 0.9 Score 0.8336182612409824\nAlpha 1.0 Score 0.8336182514567663\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n  warnings.warn(\"Numerical issues were encountered \"\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "# Lasso Regularization",
      "metadata": {
        "tags": [],
        "cell_id": "00021-603eea3b-ff6c-4b2b-90b9-78913572bd4d",
        "deepnote_cell_type": "text-cell-h1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00021-8d8933fd-3d3b-410e-bdbe-1b8ce66e1cf8",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b0dd5407",
        "execution_start": 1618928246063,
        "execution_millis": 0,
        "deepnote_cell_type": "code"
      },
      "source": "def lasso_regularization(X_train, y_train, alpha):\n    reg = Lasso(alpha=alpha)\n    reg.fit(X_train, y_train)\n    return reg.coef_, reg.intercept_, reg.score(X_train, y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00023-b30e3ec1-1909-44ab-8b0a-649b9ba74258",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "33aca4ff",
        "execution_millis": 204,
        "execution_start": 1618928262547,
        "deepnote_cell_type": "code"
      },
      "source": "data = get_clean_data(\"cleaned_data.csv\")\nX_train, y_train = preprocess_normalize_data(data)\ncoef, inter, score = lasso_regularization(X_train, y_train, 0.5)\n# print(\"Coefficients\", coef)\n# print(\"Intercept\", inter)\nprint(\"Score\", score)",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Score 0.8596074145847836\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n  warnings.warn(\"Numerical issues were encountered \"\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00024-cef94a32-8a2b-43a0-9ebb-3275ce34891f",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "eb9ff4cd",
        "execution_start": 1618928289690,
        "execution_millis": 888,
        "deepnote_cell_type": "code"
      },
      "source": "data = get_clean_data(\"cleaned_data.csv\")\nX_train, y_train = preprocess_normalize_data(data)\nridge_alpha_space = np.linspace(0,1,11)\nfor i in ridge_alpha_space:\n    coef, inter, score = lasso_regularization(X_train, y_train, i)\n    # print(\"Coefficients\", coef)\n    # print(\"Intercept\", inter)\n    print(\"Alpha\", i, \"Score\", score)",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n  warnings.warn(\"Numerical issues were encountered \"\n/shared-libs/python3.7/py-core/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n  This is separate from the ipykernel package so we can avoid doing imports until\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n  positive)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.577782554056822e+17, tolerance: 644245339634686.2\n  positive)\nAlpha 0.0 Score 0.764754757609772\nAlpha 0.1 Score 0.7647547576097717\nAlpha 0.2 Score 0.764754757609771\nAlpha 0.30000000000000004 Score 0.76475475760977\nAlpha 0.4 Score 0.764754757609768\nAlpha 0.5 Score 0.764754757609766\nAlpha 0.6000000000000001 Score 0.7647547576097633\nAlpha 0.7000000000000001 Score 0.76475475760976\nAlpha 0.8 Score 0.7647547576097562\nAlpha 0.9 Score 0.7647547576097522\nAlpha 1.0 Score 0.7647547576097473\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=90fab6ac-739b-4c97-b68c-ff3c09208031' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote": {
      "is_reactive": false
    },
    "deepnote_notebook_id": "0ab19879-2c1f-40c6-9ab2-50c74c0bd6e8",
    "deepnote_execution_queue": []
  }
}